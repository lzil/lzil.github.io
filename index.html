<!DOCTYPE html>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<head>
    <link rel="stylesheet" type="text/css" href="style.css" >
    <script type="text/javascript" src="images/photos/photos.json"></script>
    <script type="text/javascript" src="main.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/lzil/fruity.js@7a7b531bf530e667b4957f156e6e347c84021cfa/fruity.js"></script>
    <title>liang zhou</title>
</head>

<body>

<div id='menu'>
<div id='menu-box'>
    <div class='liang'>
        <span class='nav-link' id='nav-about'>liang zhou</span>
        <svg class='underName'>
            <line class='namePath' x1="0" y1="0" x2="180" y2="0" />
        </svg>
    </div>
    <span class='title-label nav-link' id='nav-research'>research</span>&nbsp;&nbsp;/&nbsp;
    <span class='title-label nav-link' id='nav-photos'>photos</span>&nbsp;&nbsp;/&nbsp;
    <span class='title-label nav-link' id='nav-etc'>etc</span>
</div>
</div>

<div id='content'>

    <!-- about page -->
    <div class='page' id='about'>
        <div class='about'>
            <br>
            <p class='font-large'>
                hello!
            </p>
            <p>
                i'm a researcher at <a class='body-link' href='https://www.openai.com'>openai</a>.
                previously, i was at ucl's <a class='body-link' href='https://www.gatsby.ucl.ac.uk'>gatsby unit</a> and <a class='body-link' href='https://www.mit.edu'>mit</a>.
            </p>
            <p>
                i like to run, dance, and travel.
            </p>
        </div>
    </div>

    <!-- research -->
    <div class='page' id='research'>
        <p>
            <b>people are fascinating.</b>
            we think, feel, act, and live as individuals in complex societies, enabled by our extraordinary cognitive abilities.
            what are the neural foundations of this so-called high-level cognition?
            <!-- <br><br>
            my research focuses on <b>skill learning</b>, ranging from basic motor movements to precise cognitive tasks. -->
<!--             <br><br>
            my primary supervisor is <a class='body-link' href="https://www.gatsby.ucl.ac.uk/~pel/">peter latham</a>; i have also worked with
            <a class='body-link' href="http://actcompthink.org/">sam mcdougle</a>,
            <a class='body-link' href="https://www.lim.bio/">athena akrami</a>,
            <a class='body-link' href="https://cicl.stanford.edu/">tobi gerstenberg</a>, and
            <a class='body-link' href="https://cocosci.mit.edu/">josh tenenbaum</a>. -->
        </p>
        <hr class='divider'>
        <div class='research'>
            <ul class='research-main-listing'>
                <li>
                    <img class='research-logo' src='images/towers2.png'>&nbsp;
                    <i>mental jenga: a counterfactual simulation model of physical support</i>
                    <br>
                    <b>zhou</b>, smith, tenenbaum, & gerstenberg
                    <br>
                    jep:g 2023 /
                    <a class="body-link" href="towers/zhou2023jenga.pdf">pdf</a>
                    <!-- <a class="body-link" href="https://psyarxiv.com/4a5uh">preprint</a> -->
                    <a class="body-link" href="https://github.com/cicl-stanford/mental_jenga">code</a>
                    <a class="body-link" href="https://cicl-stanford.github.io/mental_jenga/interface/">visualization</a>
                    

                    <br>
                    <span class='research-down-arrow'>&#8231; &#8231; &#8231;</span>
                    <p class='research-desc'>
                        we model people's judgments of physical stability using
                        a noisy physics engine that simulates counterfactual possibilities.
                        we ran experiments testing people's judgments of selection, prediction, and responsibility
                        in order to probe their beliefs about stability and confirmed the utility
                        of our model.
                    </p>
                </li>

                <li>
                    <img class='research-logo' src='images/sound-cat2.png'>&nbsp;
                    <i>sensory priors, and choice and outcome history in service of optimal behaviour in noisy environments</i>
                    <br>
                    pedrosa, menichini, pajot-moric, <b>zhou</b>, latham, & akrami
                    <br>
                    cosyne 2023
                    <br>
                    <span class='research-down-arrow'>&#8231; &#8231; &#8231;</span>
                    <p class='research-desc'>
                        we analyze behavior in an auditory categorization task in humans, mice and rats, and compare this behavior to that of models trained on the same task.
                        we also investigate the sources of particular biases that appear in the behavior.
                    </p>
                </li>

                <li>
                    <img class='research-logo' src='images/sound-cat.png'>&nbsp;
                    <i>decisions are guided by learning and perceptual biases in a 2-alternative-forced-choice task</i>
                    <br>
                    <b>zhou</b>, pedrosa, menichini, latham, & akrami
                    <br>
                    rldm 2022
                    <br>
                    <span class='research-down-arrow'>&#8231; &#8231; &#8231;</span>
                    <p class='research-desc'>
                        animals integrate sensory evidence to make decisions.
                        over multiple trials, they also infer the statistics of sensory stimuli.
                        here, we analyze how such statistics affect performance in a perceptual categorization task in humans and rats.
                        we construct models that simulate normative agents behaving based on different first principles.
                    </p>
                </li>
                
                <li>
                    <img class='research-logo' src='images/res-input.png'>&nbsp;
                    <i>learning sensory representations for flexible computation with recurrent circuits</i>
                    <br>
                    <b>zhou</b>, menendez, & latham
                    <br>
                    cosyne 2021
                    <br>
                    <span class='research-down-arrow'>&#8231; &#8231; &#8231;</span>
                    <p class='research-desc'>
                        trained rnns can perform all sorts of behaviorally relevant tasks, such as the ready-set-go task.
                        we show here that randomly initialized untrained reservoirs can also perform such tasks
                        if an additional linear mapping is learned between the input and recurrent layers.
                        this drastically reduces the number of parameters that need to be tuned.
                    </p>
                </li>

                <li>
                    <img class='research-logo' src='images/kale.png'>&nbsp;
                    <i>generalized energy based models</i>
                    <br>
                    arbel, <b>zhou</b>, & gretton
                    <br>
                    iclr 2021 /
                    <a class="body-link" href="https://arxiv.org/abs/2003.05033">arxiv</a>
                    <br>
                    <span class='research-down-arrow'>&#8231; &#8231; &#8231;</span>
                    <p class='research-desc'>
                        we combine desirable properties of ebms and gans.
                        we introduce the kale, which is a lower bound on the kl that is smooth and can be estimated from samples.
                        after training a gan with kale, we can perform langevin sampling on the output of the generator to produce
                        higher-quality images than those obtainable from the generator alone.
                    </p>
                </li>

                <li>
                    <img class='research-logo' src='images/towers.png'>&nbsp;
                    <i>faulty towers: a hypothetical simulation model of physical support</i>
                    <br>
                    gerstenberg, <b>zhou</b>, smith, & tenenbaum
                    <br>
                    cogsci 2017 [talk] /
                    <a class="body-link" href="towers/towers.pdf">paper</a>
                    <a class="body-link" href="towers/physics_interface.html">visualization</a>
                    <br>
                    <span class='research-down-arrow'>&#8231; &#8231; &#8231;</span>
                    <p class='research-desc'>
                        we model people's judgments of physical stability using
                        a noisy physics engine that can simulate possible counterfactuals.
                        we ran several mturk experiments and confirmed that our approach better
                        modeled intuitive human judgments.
                    </p>
                </li>

                <li>
                    <img class='research-logo' src='images/hairs.png'>&nbsp;
                    <i>methods of 3d printing micro-pillar structures on surfaces</i>
                    <br>
                    ou, cheng, <b>zhou</b>, dublon, & ishii
                    <br>
                    uist 2015 /
                    <a href='http://dl.acm.org/citation.cfm?id=2817812' class='body-link'>paper</a>
                    <a href='http://www.freepatentsonline.com/10509559.html' class='body-link'>patent</a>
                    <br>
                    <span class='research-down-arrow'>&#8231; &#8231; &#8231;</span>
                    <p class='research-desc'>
                        i wrote a java processing suite to model the geometry of 3d-printed high-resolution micropillar structures,
                        which can collectively bend to represent a vector field. using a prepared image as input, we output a
                        representation of the resulting structure based on image gradient properties.
                    </p>
                </li>
            </ul>
        </div>
    </div>

    <!-- photos -->
    <div class='page' id='photos'>
        <p>
            just a collection of snapshots in time and space
        </p>
        <!-- <hr class='divider'> -->
        
        <div class='photos'>
            <div class='photo-tab all-photos'></div>
        </div>
    </div>
    
    <!-- etc things page -->
    <div class='page' id='etc'>
        <div class='etc'>
            <p><a class='body-link' href='plzplaywithme/index.html'>plz play with me &lt;3</a></p>
            <p>type <span class='code'>fruit</span> to fruitify this site</p>
            <br>
            <hr class='divider'>
            <p class='font-small'>
                liang at org dot com<br>
                last updated 12 sep 24
            </p>
        </div>
    </div>

    <br><br>

</div>

</body>
</html>
